{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ensemble_multiclass.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGP7IavbQidi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ba067a5d-67d1-4783-832c-cac5b523380d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wt2WdvbqPV2g",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential, Model, Input, load_model\n",
        "from tensorflow.python.framework.ops import Tensor\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation, Average\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import tensorboard \n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing import image\n",
        "from keras.applications import VGG16\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt \n",
        "from sklearn import model_selection, metrics\n",
        "from keras.utils import to_categorical\n",
        "import seaborn as sn\n",
        "import pickle\n",
        "from statistics import mode\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "import sklearn\n",
        "import glob\n",
        "from numpy import ravel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUVANKoLNmt0",
        "colab_type": "text"
      },
      "source": [
        "#If you want to save weight files for future use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xYkRWZAAPZ52",
        "colab": {}
      },
      "source": [
        "CONV_POOL_CNN_WEIGHT_FILE = os.path.join(os.getcwd(), 'conv_pool_cnn_pretrained_weights.hdf5')\n",
        "ALL_CNN_WEIGHT_FILE = os.path.join(os.getcwd(), 'all_cnn_pretrained_weights.hdf5')\n",
        "NIN_CNN_WEIGHT_FILE = os.path.join(os.getcwd(), 'nin_cnn_pretrained_weights.hdf5')\n",
        "NEW_NIN_CNN_WEIGHT_FILE = os.path.join(os.getcwd(), 'new_nin_cnn_pretrained_weights.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AgB310mNsc2",
        "colab_type": "text"
      },
      "source": [
        "#Dataset filepaths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1Cr5J_XLPV2n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "73e225f9-956a-4187-8dcf-a01a5df75b70"
      },
      "source": [
        "img_filename = '/content/drive/My Drive/multi_bee_images_1_highres.pickle'\n",
        "second_img_filename = '/content/drive/My Drive/multi_bee_images_2_highres.pickle'\n",
        "\n",
        "label_filename = '/content/drive/My Drive/multi_labels_1.pickle'\n",
        "second_label_filename = '/content/drive/My Drive/multi_labels_2.pickle'\n",
        "\n",
        "\"\"\"img_filename = 'images_1_highres.pickle'\n",
        "second_img_filename = 'images_2_highres.pickle'\n",
        "\n",
        "label_filename = 'labels_1.pickle'\n",
        "second_label_filename = 'labels_2.pickle'\"\"\"\n",
        "\n",
        "with open(img_filename, 'rb') as source:\n",
        "    first_imgs = pickle.load(source)\n",
        "with open(second_img_filename, 'rb') as source:\n",
        "    second_imgs = pickle.load(source)\n",
        "\n",
        "X = np.concatenate((first_imgs,second_imgs),axis=0)\n",
        "\n",
        "with open(label_filename, 'rb') as source:\n",
        "    first_labels = pickle.load(source)\n",
        "with open(second_label_filename, 'rb') as source:\n",
        "    second_labels = pickle.load(source)\n",
        "\n",
        "y = np.concatenate((first_labels,second_labels),axis=0)\n",
        "print(set(y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'1 Mixed local stock 2', 'Bombus bimaculatus', 'Bombus perplexus', 'Russian honey bee', 'Bombus affinis', 'Western honey bee', 'Bombus griseocollis', 'Bombus citrinus', 'Bombus auricomus', 'Italian honey bee', 'Carniolan honey bee', 'Apis mellifera', 'Bombus impatiens', 'Bombus vagans', 'Bombus rufocinctus', 'VSH Italian honey bee', 'Bombus fraternus', 'Bombus fervidus', 'Bombus pensylvanicus'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idM9C6Z0NwsG",
        "colab_type": "text"
      },
      "source": [
        "#Remove classes with under 200 samples\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HNhENKu_PV2p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b5f2be72-9c45-49ae-976d-367056795cf2"
      },
      "source": [
        "classes_to_remove = ['Bombus fraternus','Bombus perplexus']\n",
        "indices_to_remove = []\n",
        "for i,label in enumerate(y):\n",
        "  if label in classes_to_remove:\n",
        "    indices_to_remove.append(i)\n",
        "\n",
        "y = np.delete(y,indices_to_remove)\n",
        "X = np.delete(X,indices_to_remove,axis=0)\n",
        "\n",
        "#rename apis mellifera to western honey bee\n",
        "y = np.where(y=='Apis mellifera','Western honey bee',y)\n",
        "print(set(y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'1 Mixed local stock 2', 'Bombus bimaculatus', 'Russian honey bee', 'Bombus affinis', 'Western honey bee', 'Bombus griseocollis', 'Bombus citrinus', 'Bombus auricomus', 'Italian honey bee', 'Carniolan honey bee', 'Bombus impatiens', 'Bombus vagans', 'Bombus rufocinctus', 'VSH Italian honey bee', 'Bombus fervidus', 'Bombus pensylvanicus'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MpreJDE8PV2r",
        "colab": {}
      },
      "source": [
        "bee_names = np.array(y)\n",
        "assert(len(X)==len(y))\n",
        "number_classes = len(set(y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AcqXXenN0w3",
        "colab_type": "text"
      },
      "source": [
        "#Undersample classes over 1,000 down to 1,000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c1XcmlnVPV2t",
        "colab": {}
      },
      "source": [
        "undersampling_counts = {'1 Mixed local stock 2': 472,\n",
        " 'Bombus affinis': 462,\n",
        " 'Bombus auricomus': 1000,\n",
        " 'Bombus bimaculatus': 1000,\n",
        " 'Bombus citrinus': 241,\n",
        " 'Bombus fervidus': 774,\n",
        " 'Bombus griseocollis': 1000,\n",
        " 'Bombus impatiens': 1000,\n",
        " 'Bombus pensylvanicus': 742,\n",
        " 'Bombus rufocinctus': 199,\n",
        " 'Bombus vagans': 287,\n",
        " 'Carniolan honey bee': 501,\n",
        " 'Italian honey bee': 1000,\n",
        " 'Russian honey bee': 527,\n",
        " 'VSH Italian honey bee': 199,\n",
        " 'Western honey bee': 1000}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-Z4-z0hNPV2w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8c893c44-6819-49d8-f892-c3326140779c"
      },
      "source": [
        "#Undersampling \n",
        "index_list = np.array([i for i in range(len(X))])\n",
        "rus = RandomUnderSampler(random_state=42, sampling_strategy=undersampling_counts)\n",
        " \n",
        "Xresampled, yresampled = rus.fit_resample(\n",
        "    index_list.reshape(-1, 1), y\n",
        ")\n",
        "Xresampled = Xresampled.flatten()\n",
        "print(Xresampled.shape)\n",
        "Xresampled = X[Xresampled]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10404,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5jel54RN6NK",
        "colab_type": "text"
      },
      "source": [
        "#SMOTE oversampling up to 1000 samples\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ksLryyVE8C3U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "466b3d20-aee0-4842-d16f-beb8f02d53ea"
      },
      "source": [
        "index_list_again = np.array([i for i in range(len(Xresampled))])\n",
        "sm = SMOTE(random_state=42)\n",
        " \n",
        "Xresampled_again, yresampled_again = sm.fit_resample(index_list_again.reshape(-1, 1), yresampled)\n",
        "Xresampled_again = Xresampled_again.flatten()\n",
        "print(Xresampled_again.shape)\n",
        "Xresampled_again = Xresampled[Xresampled_again]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5mu2-2GOGLz",
        "colab_type": "text"
      },
      "source": [
        "#Make text labels into numbers for one-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bzkO2IVW8DDq",
        "colab": {}
      },
      "source": [
        "label_to_number = {'1 Mixed local stock 2': 0,\n",
        " 'Bombus affinis': 1,\n",
        " 'Bombus auricomus': 2,\n",
        " 'Bombus bimaculatus': 3,\n",
        " 'Bombus citrinus': 4,\n",
        " 'Bombus fervidus': 5,\n",
        " 'Bombus griseocollis': 6,\n",
        " 'Bombus impatiens': 7,\n",
        " 'Bombus pensylvanicus': 8,\n",
        " 'Bombus rufocinctus': 9,\n",
        " 'Bombus vagans': 10,\n",
        " 'Carniolan honey bee': 11,\n",
        " 'Italian honey bee': 12,\n",
        " 'Russian honey bee': 13,\n",
        " 'VSH Italian honey bee': 14,\n",
        " 'Western honey bee': 15}\n",
        "\n",
        "inv_bee_dict = {v:k for k,v in label_to_number.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7sGKZzB_8DLH",
        "colab": {}
      },
      "source": [
        "number_y = []\n",
        "for label in yresampled_again:\n",
        "  new_label = label_to_number[label]\n",
        "  number_y.append(new_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKydLz-gODcZ",
        "colab_type": "text"
      },
      "source": [
        "#Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WrfqE6D28IN9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "338df65c-ec29-4b2b-d333-54a5b6e1a32a"
      },
      "source": [
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
        "    Xresampled_again, number_y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f'Files in train: {len(X_train)}. Files in test: {len(X_test)}')\n",
        "\n",
        "y_test = to_categorical(y_test)\n",
        "y_train = to_categorical(y_train)\n",
        "np.unique(y_test)\n",
        "input_shape = X_train[0,:,:,:].shape\n",
        "model_input = Input(shape=input_shape)\n",
        "print(f'Input shape: {input_shape}')\n",
        "print(f'Model input: {model_input}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files in train: 12800. Files in test: 3200\n",
            "Input shape: (64, 64, 3)\n",
            "Model input: Tensor(\"input_2:0\", shape=(?, 64, 64, 3), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfvGdIY4OTJj",
        "colab_type": "text"
      },
      "source": [
        "#Image augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gGKt63zA8KCK",
        "colab": {}
      },
      "source": [
        "datagen = image.ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,)\n",
        "\n",
        "datagen.fit(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjvN54fHOU_c",
        "colab_type": "text"
      },
      "source": [
        "#If you want to save the model, not the weights. Choose between data augmentation and no data augmention. Returns 2 objects: model and history"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4-LoscQn04CC",
        "colab": {}
      },
      "source": [
        "def NO_WEIGHTS_compile_and_train(model,model_name, num_epochs): \n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc']) \n",
        "    #history = model.fit_generator(datagen.flow(X_train,y_train,batch_size=32),steps_per_epoch=(len(X_train)),\n",
        "     #                             validation_data=(X_test,y_test),epochs=num_epochs, verbose=1)\n",
        "    history = model.fit(x=X_train, y=y_train, batch_size=32, \n",
        "                     epochs=num_epochs, verbose=1,validation_split=0.15)\n",
        "    model.save(model_name +'.h5')\n",
        "    return model,history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCQOlYkhOesl",
        "colab_type": "text"
      },
      "source": [
        "#This will save your weight files. Choose between data augmentation and no data augmention. Returns 3 objects: model, history and weight file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lnk_t5Sw1Y1N",
        "colab": {}
      },
      "source": [
        "def compile_and_train(model,model_name,num_epochs): \n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc']) \n",
        "    filepath = model_name + '.{epoch:02d}-{loss:.2f}.hdf5'\n",
        "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_weights_only=True,\n",
        "                                                 save_best_only=True, mode='auto', period=1)\n",
        "    tensor_board = keras.callbacks.TensorBoard(log_dir='logs/', histogram_freq=0, batch_size=32)\n",
        "    #history = model.fit_generator(datagen.flow(X_train,y_train,batch_size=32),steps_per_epoch=(len(X_train)),\n",
        "     #                             validation_data=(X_test,y_test),epochs=num_epochs, verbose=1,callbacks=[checkpoint, tensor_board])\n",
        "    history = model.fit(x=X_train, y=y_train, batch_size=32, \n",
        "                     epochs=num_epochs, verbose=1, callbacks=[checkpoint, tensor_board])\n",
        "    weight_files = glob.glob(os.path.join(os.getcwd(), 'weights/*'))\n",
        "    weight_file = max(weight_files, key=os.path.getctime) # most recent file\n",
        "    return model,history, weight_file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lu4_UIseZLJr",
        "colab_type": "text"
      },
      "source": [
        "#Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "58RKlZM_TK2C",
        "colab": {}
      },
      "source": [
        "def make_training_loss_accuracy(model_history, epochs):\n",
        "  ax = plt.subplot(111)\n",
        "  # Hide the right and top spines\n",
        "  ax.spines['right'].set_visible(False)\n",
        "  ax.spines['top'].set_visible(False)\n",
        "  ax.plot(list(range(1,epochs + 1)), model_history.history['acc'], label = 'training accuracy')\n",
        "  ax.plot(list(range(1,epochs + 1)), model_history.history['loss'], label = 'training loss')\n",
        "  plt.xlabel('epoch number', fontsize = 16)\n",
        "  plt.ylabel('training accuracy', fontsize = 14)\n",
        "  ax.set_title(\"Training Accuracy and Loss per Epoch\", fontsize = 20, pad = 40)\n",
        "  plt.xticks(list(range(5, epochs+1, 5)))\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsfYy3ShTQ3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_ypred_and_ytest(model,X_test,y_test):\n",
        "    model.evaluate(X_test,y_test)\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred = np.argmax(y_pred,axis=1)\n",
        "    #reduce the one hot encodings\n",
        "    y_truth = np.where(y_test==1)[1]\n",
        "    return y_pred, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSeY_kpjUT2K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_classifiation_report_and_cm(y_pred,y_test,inv_bee_dict):\n",
        "  y_test = np.where(y_test==1)[1]\n",
        "  classes = set(y_test)\n",
        "  print(classification_report(y_test, y_pred))\n",
        "  bee_list = []\n",
        "  for i in range(len(classes)):\n",
        "      bee_list.append(inv_bee_dict[i])\n",
        "      \n",
        "  cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "  sn_cm = sn.heatmap(cm, annot=False,xticklabels=bee_list,yticklabels=bee_list)\n",
        "  print(sn_cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AyxbwYj1o4ki",
        "colab": {}
      },
      "source": [
        "# Compute ROC curve and ROC area for each class\n",
        "\n",
        "def make_ROC(y_pred,y_test,inv_bee_dict):\n",
        "  y_truth = np.where(y_test==1)[1]\n",
        "  classes = set(y_truth)\n",
        "  lb = sklearn.preprocessing.LabelBinarizer()\n",
        "  y_truth = lb.fit_transform(y_test)\n",
        "  y_pred = lb.fit_transform(y_pred)\n",
        "  fpr = dict()\n",
        "  tpr = dict()\n",
        "  roc_auc = dict()\n",
        "\n",
        "  for i in range(len(classes)):\n",
        "      fpr[i], tpr[i], _ = sklearn.metrics.roc_curve(y_truth[:, i], y_pred[:,i])\n",
        "      roc_auc[i] = sklearn.metrics.auc(fpr[i], tpr[i])\n",
        "\n",
        "  # Compute micro-average ROC curve and ROC area\n",
        "  fpr[\"micro\"], tpr[\"micro\"], _ = sklearn.metrics.roc_curve(y_truth.ravel(), y_pred.ravel())\n",
        "  roc_auc[\"micro\"] = sklearn.metrics.auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "  plt.figure(figsize=(12,12))\n",
        "  lw = 1\n",
        "  for i in range(len(classes)):\n",
        "    class_name = inv_bee_dict[i]\n",
        "    plt.plot(fpr[i], tpr[i], \n",
        "            color=np.random.rand(3,),lw=lw, label=class_name + ' ROC AUC = %0.2f' % roc_auc[i])\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.0])\n",
        "    plt.xlabel('False Positive Rate/1-Specificity')\n",
        "    plt.ylabel('True Positive Rate/Sensitivity')\n",
        "    plt.title('ROC - mini batches adam optimizer with dropout, and batch normalization')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g6cxnrAh7bM4"
      },
      "source": [
        "#Convoluational Pool CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QIkRsSsdQAXo",
        "colab": {}
      },
      "source": [
        "def conv_pool_cnn(model_input):\n",
        "    \n",
        "    x = Conv2D(96, kernel_size=(3, 3), activation='relu', padding = 'same')(model_input)\n",
        "    x = Conv2D(96, (3, 3), activation='relu', padding = 'same')(x)\n",
        "    x = Conv2D(96, (3, 3), activation='relu', padding = 'same')(x)\n",
        "    x = MaxPooling2D(pool_size=(3, 3), strides = 2)(x)\n",
        "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
        "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
        "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
        "    x = MaxPooling2D(pool_size=(3, 3), strides = 2)(x)\n",
        "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
        "    x = Conv2D(192, (1, 1), activation='relu')(x)\n",
        "    x = Conv2D(16, (1, 1))(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Activation(activation='softmax')(x)\n",
        "    \n",
        "    model = Model(model_input, x, name='conv_pool_cnn')\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AyLwL2rj7bNA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "4b8f3b8e-1750-401b-fba0-d17c216f0677"
      },
      "source": [
        "NUM_EPOCHS = 20\n",
        "conv_pool_cnn_model = conv_pool_cnn(model_input)\n",
        "conv_model, conv_history, conv_pool_cnn_weight_file = compile_and_train(conv_pool_cnn_model, 'conv_pool_cnn', NUM_EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "12800/12800 [==============================] - 21s 2ms/step - loss: 2.3006 - acc: 0.1641\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-7aab5478defd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mconv_pool_cnn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_pool_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mconv_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_pool_cnn_weight_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompile_and_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_pool_cnn_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'conv_pool_cnn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-76-f99e92cab5e6>\u001b[0m in \u001b[0;36mcompile_and_train\u001b[0;34m(model, model_name, num_epochs)\u001b[0m\n\u001b[1;32m      9\u001b[0m      \u001b[0;31m#                             validation_data=(X_test,y_test),epochs=num_epochs, verbose=1,callbacks=[checkpoint, tensor_board])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     history = model.fit(x=X_train, y=y_train, batch_size=32, \n\u001b[0;32m---> 11\u001b[0;31m                      epochs=num_epochs, verbose=1, callbacks=[checkpoint, tensor_board])\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mweight_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'weights/*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mweight_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetctime\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# most recent file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    222\u001b[0m                         \u001b[0mepoch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    715\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36msave_wrapper\u001b[0;34m(obj, filepath, overwrite, *args, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0msave_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msave_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36msave_weights\u001b[0;34m(self, filepath, overwrite)\u001b[0m\n\u001b[1;32m   1168\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mproceed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1171\u001b[0m             \u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights_to_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;31m# Open in append mode (read/write).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to create file (unable to open file: name = 'weights/conv_pool_cnn.01-2.30.hdf5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVEJh8M3SNi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "make_training_loss_accuracy(conv_history,20)\n",
        "conv_y_pred,conv_y_truth = make_ypred_and_ytest(conv_model,X_test,y_test)\n",
        "make_classifiation_report_and_cm(conv_y_pred,conv_y_truth,inv_bee_dict)\n",
        "make_ROC(conv_y_pred,conv_y_truth,inv_bee_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKRJnnosU3Kl",
        "colab_type": "text"
      },
      "source": [
        "#All CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VsS8Ii4KPV2y",
        "colab": {}
      },
      "source": [
        "def all_cnn(model_input):\n",
        "    \n",
        "    x = Conv2D(96, kernel_size=(3, 3), activation='relu', padding = 'same')(model_input)\n",
        "    x = Conv2D(96, (3, 3), activation='relu', padding = 'same')(x)\n",
        "    x = Conv2D(96, (3, 3), activation='relu', padding = 'same', strides = 2)(x)\n",
        "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
        "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
        "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same', strides = 2)(x)\n",
        "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
        "    x = Conv2D(192, (1, 1), activation='relu')(x)\n",
        "    x = Conv2D(16, (1, 1))(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Activation(activation='softmax')(x)\n",
        "        \n",
        "    model = Model(model_input, x, name='all_cnn')\n",
        "    \n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K4s5CB3P1eKU",
        "colab": {}
      },
      "source": [
        "NUM_EPOCHS = 20\n",
        "all_cnn_model = all_cnn(model_input)\n",
        "cnn_model, cnn_history, all_cnn_weight_file = compile_and_train(all_cnn_model,'all_cnn', NUM_EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1-YjE52Zdfp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "make_training_loss_accuracy(cnn_history,20)\n",
        "cnn_y_pred,cnn_y_truth = make_ypred_and_ytest(cnn_model,X_test,y_test)\n",
        "make_classifiation_report_and_cm(cnn_y_pred,cnn_y_truth,inv_bee_dict)\n",
        "make_ROC(cnn_y_pred,cnn_y_truth,inv_bee_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPzZJmQcU5kM",
        "colab_type": "text"
      },
      "source": [
        "#NIN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XeLLUUCRPV23",
        "colab": {}
      },
      "source": [
        "def nin_cnn(model_input):\n",
        "    \n",
        "    #mlpconv block 1\n",
        "    x = Conv2D(32, (5, 5), activation='relu',padding='valid')(model_input)\n",
        "    x = Conv2D(32, (1, 1), activation='relu')(x)\n",
        "    x = Conv2D(32, (1, 1), activation='relu')(x)\n",
        "    x = MaxPooling2D((2,2))(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    \n",
        "    #mlpconv block2\n",
        "    x = Conv2D(64, (3, 3), activation='relu',padding='valid')(x)\n",
        "    x = Conv2D(64, (1, 1), activation='relu')(x)\n",
        "    x = Conv2D(64, (1, 1), activation='relu')(x)\n",
        "    x = MaxPooling2D((2,2))(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    \n",
        "    #mlpconv block3\n",
        "    x = Conv2D(128, (3, 3), activation='relu',padding='valid')(x)\n",
        "    x = Conv2D(32, (1, 1), activation='relu')(x)\n",
        "    x = Conv2D(16, (1, 1))(x)\n",
        "    \n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Activation(activation='softmax')(x)\n",
        "    \n",
        "    model = Model(model_input, x, name='nin_cnn')\n",
        "    \n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5SfNdA4x1hr7",
        "colab": {}
      },
      "source": [
        "NUM_EPOCHS = 20\n",
        "nin_cnn_model = nin_cnn(model_input)\n",
        "nin_model, nin_history, nin_cnn_weight_file = compile_and_train(nin_cnn_model,'nin',NUM_EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoV0i8l8aGnb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "make_training_loss_accuracy(nin_history,20)\n",
        "nin_y_pred,nin_y_truth = make_ypred_and_ytest(nin_model,X_test,y_test)\n",
        "make_classifiation_report_and_cm(nin_y_pred,nin_y_truth,inv_bee_dict)\n",
        "make_ROC(nin_y_pred,nin_y_truth,inv_bee_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhweJjriaYvq",
        "colab_type": "text"
      },
      "source": [
        "#Improved NIN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yhw_JgsWaSli",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def new_nin_cnn(model_input):\n",
        "    \n",
        "    #mlpconv block 1\n",
        "    x = Conv2D(32, (5, 5), activation='relu',padding='valid')(model_input)\n",
        "    x = Conv2D(32, (1, 1), activation='relu')(x)\n",
        "    x = Conv2D(32, (3, 3), activation='relu')(x)\n",
        "    x = Conv2D(64, (1, 1), activation='relu')(x)\n",
        "    x = MaxPooling2D((2,2))(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    \n",
        "    #mlpconv block2\n",
        "    x = Conv2D(64, (3, 3), activation='relu',padding='valid')(x)\n",
        "    x = Conv2D(64, (1, 1), activation='relu')(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "    x = Conv2D(128, (1, 1), activation='relu')(x)\n",
        "    x = MaxPooling2D((2,2))(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    \n",
        "    #mlpconv block3\n",
        "    x = Conv2D(128, (3, 3), activation='relu',padding='valid')(x)\n",
        "    x = Conv2D(64, (1, 1), activation='relu')(x)\n",
        "    x = Conv2D(16, (1, 1), activation='relu')(x)\n",
        "\n",
        "    \n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Activation(activation='softmax')(x)\n",
        "    \n",
        "    model = Model(model_input, x, name='nin_cnn')\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKxAKUIOaedn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_EPOCHS = 20\n",
        "new_nin_cnn_model = new_nin_cnn(model_input)\n",
        "new_nin_model, new_nin_history, new_nin_cnn_weight_file = compile_and_train(new_nin_cnn_model, 'new_nin', NUM_EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiHZF0EnangK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "make_training_loss_accuracy(new_nin_history,20)\n",
        "new_nin_y_pred,new_nin_y_truth = make_ypred_and_ytest(new_nin_model,X_test,y_test)\n",
        "make_classifiation_report_and_cm(new_nin_y_pred,new_nin_y_truth,inv_bee_dict)\n",
        "make_ROC(new_nin_y_pred,new_nin_y_truth,inv_bee_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlXMyzMIkaOv",
        "colab_type": "text"
      },
      "source": [
        "#Ensemble predit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wn0fzZ46tqBT",
        "colab": {}
      },
      "source": [
        "conv_pool_cnn_model = conv_pool_cnn(model_input)\n",
        "all_cnn_model = all_cnn(model_input)\n",
        "nin_cnn_model = nin_cnn(model_input)\n",
        "new_nin_cnn_model = new_nin_cnn(model_input)\n",
        "\n",
        "try:\n",
        "    conv_pool_cnn_model.load_weights(conv_pool_cnn_weight_file)\n",
        "except NameError:\n",
        "    conv_pool_cnn_model.load_weights(CONV_POOL_CNN_WEIGHT_FILE)\n",
        "try:\n",
        "    all_cnn_model.load_weights(all_cnn_weight_file)\n",
        "except NameError:\n",
        "    all_cnn_model.load_weights(ALL_CNN_WEIGHT_FILE)\n",
        "try:\n",
        "    nin_cnn_model.load_weights(nin_cnn_weight_file)\n",
        "except NameError:\n",
        "    nin_cnn_model.load_weights(NIN_CNN_WEIGHT_FILE)\n",
        "try:\n",
        "    new_nin_cnn_model.load_weights(new_nin_cnn_weight_file)\n",
        "except NameError:\n",
        "    new_nin_cnn_model.load_weights(NEW_NIN_CNN_WEIGHT_FILE)\n",
        "\n",
        "\n",
        "models = [conv_pool_cnn_model, all_cnn_model, nin_cnn_model,new_nin_cnn_model]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hVRB4H_xz6Kd",
        "colab": {}
      },
      "source": [
        "def ensemble(models, model_input):\n",
        "    \n",
        "    outputs = [model.outputs[0] for model in models]\n",
        "    y = Average()(outputs)\n",
        "    model = Model(model_input, y, name='ensemble')\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x93O1cTL2MXT",
        "colab": {}
      },
      "source": [
        "ensemble_model = ensemble(models, model_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9oC-ws8_2qXo",
        "colab": {}
      },
      "source": [
        "def evaluate_error(model):\n",
        "    pred = model.predict(X_test, batch_size = 32)\n",
        "    pred = np.argmax(pred, axis=1)\n",
        "    pred = np.expand_dims(pred, axis=1) # make same shape as y_test\n",
        "    error = np.sum(np.not_equal(pred, y_test)) / y_test.shape[0]\n",
        "    cr = classification_report(pred,y_test)    \n",
        "    return error, cr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CpS5x5Sp3c3J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e36fd7f8-dd5c-4b59-9781-d638b1d7b5f0"
      },
      "source": [
        "evaluate_error(ensemble_model)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17.99974817426341"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QluHGhiY3fDT",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}